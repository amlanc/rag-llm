{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T19:56:13.603315Z",
     "start_time": "2024-05-11T19:56:12.853806Z"
    }
   },
   "source": [
    "import importlib.util\n",
    "\n",
    "#import lancedb\n",
    "from langchain.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.vectorstores import lancedb\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "import importlib\n",
    "import nltk\n",
    "import ssl\n",
    "import os\n",
    "from langchain import HuggingFaceHub\n",
    "\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "\n",
    "\n",
    "import textwrap"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-05-11T19:56:13.606653Z",
     "start_time": "2024-05-11T19:56:13.604522Z"
    }
   },
   "source": [
    "print(f\"Current dir: {os.path.abspath(os.path.curdir)}\")\n",
    "# os.environ['OPENAI_API_KEY'] = ''\n",
    "# os.environ['HUGGINGFACEHUB_API_TOKEN'] = ''\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current dir: /Users/amlanchatterjee/PycharmProjects/rag-llm/com/5r/rag\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-05-11T19:56:16.230880Z",
     "start_time": "2024-05-11T19:56:13.607347Z"
    }
   },
   "source": [
    "#Disable ssl certificate verification\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "#Download nltk modules if not there\n",
    "if os.path.isfile(\"/Users/amlanchatterjee/nltk_data/corpora/wordnet.zip\") is None:\n",
    "    nltk.download('wordnet')\n",
    "\n",
    "if os.path.isfile(\"/Users/amlanchatterjee/nltk_data/tokenizers/punkt.zip\") is None:\n",
    "    nltk.download('punkt')\n",
    "\n",
    "pdf_folder_path=\"data\"\n",
    "loader = PyPDFDirectoryLoader(pdf_folder_path)\n",
    "raw_pdf_doc = loader.load()"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-05-11T19:56:16.238700Z",
     "start_time": "2024-05-11T19:56:16.231480Z"
    }
   },
   "source": [
    "print(\"Splitting PDF Document text..\")\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1024, chunk_overlap=16)\n",
    "texts = text_splitter.split_documents(raw_pdf_doc)\n",
    "print(f\"Document splitting completed.. [{texts.__len__()}] splits\")\n",
    "##print(f\"{texts}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting PDF Document text..\n",
      "Document splitting completed.. [303] splits\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-05-11T19:56:16.241924Z",
     "start_time": "2024-05-11T19:56:16.240287Z"
    }
   },
   "source": [
    "print(\"Loading Embeddings...\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Embeddings...\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "is_executing": true
    },
    "scrolled": true,
    "pycharm": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-05-11T19:56:16.242633Z"
    }
   },
   "source": [
    "# # select which embeddings we want to use\n",
    "# # embeddings = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2', model_kwargs={'device': 'cpu'})\n",
    "embeddings = HuggingFaceEmbeddings()\n",
    "#embeddings = OpenAIEmbeddings()\n",
    "print(\"Embeddings loaded\")\n",
    "#\n",
    "# # create the vector store to use for indexing\n",
    "# dbhost=\"\"\n",
    "# user=\"\"\n",
    "# url=\"redis://\" + user + \"@\" + dbhost\n",
    "# vectordb = Redis.from_documents(texts, embeddings, redis_url=url, index_name=\"link\")\n",
    "# vectordb = FAISS.load_local(folder_path=\"data\", embeddings=embeddings, index_name='index', allow_dangerous_deserialization=True)\n",
    "#vectordb = FAISS.from_texts(texts, embeddings)\n",
    "#vectordb = Chroma.from_documents(texts, embeddings)\n",
    "#\n",
    "vectordb = lancedb.LanceDB.from_documents(texts, embeddings)\n",
    "print(f\"db created and loaded with split documents {vectordb}\")\n",
    "#query = \"How to see extended capture data in X2D?\"\n",
    "query = \"How to use Gradient tool in phocus?\"\n",
    "#\n",
    "#docs_and_scores = db.similarity_search(query)\n",
    "\n",
    "#embedding_vector = OpenAIEmbeddings().embed_query(query)\n",
    "query_vec_embedding = embeddings.embed_query(query)\n",
    "print(f\"Query embedding vector created: {query_vec_embedding[0]} ...\")\n",
    "print(f\"Query = {query}\\n\")\n",
    "# result = db.similarity_search_with_relevance_scores(embedding_vector, embeddings)\n",
    "# result = db.similarity_search_by_vector(embedding_vector, embeddings)\n",
    "# result = await vectordb.asimilarity_search_by_vector(query_vec_embedding)\n",
    "\n",
    "## WORKS\n",
    "result = await vectordb.asimilarity_search(query)\n",
    "print(f\"Result: {result[0].page_content.splitlines(keepends=False)}\\n\")\n",
    "# print(f\"Result: {result[1].page_content.splitlines(keepends=False)}\\n\")\n",
    "# for i in range(len(result)):\n",
    "#     print(f\"Result: {result[i].page_content.splitlines(keepends=False)}\")\n",
    "\n",
    "#####\n",
    "retriever = vectordb.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":1})\n",
    "# print(f\"Retriever: {retriever.__pretty__}\")\n",
    "#\n",
    "print(\"downloading LLM model\")\n",
    "\n",
    "try:\n",
    "    llm=HuggingFaceHub(repo_id=\"google/flan-t5-xxl\", model_kwargs={\"temperature\":1, \"max_length\":1024})\n",
    "\n",
    "except Exception as e:\n",
    "    print({e})\n",
    "\n",
    "print(\"Successfully Loaded llm model\")\n",
    "\n",
    "print(\"Loading QA...\")\n",
    "try:\n",
    "    qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=retriever, return_source_documents=True)\n",
    "    ans = qa({\"query\": \"query\"})\n",
    "    print(f\"Answer recewived is \\n f{ans}\")\n",
    "except Exception as x:\n",
    "    print({x})\n",
    "\n",
    "print(\"QA answered\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings loaded\n",
      "db created and loaded with split documents <langchain_community.vectorstores.lancedb.LanceDB object at 0x3203621d0>\n",
      "Query embedding vector created: 0.021041328087449074 ...\n",
      "Query = How to use Gradient tool in phocus?\n",
      "\n",
      "Result: ['USER GUIDEwww.hasselblad.com', 'Phocus82', 'Table of ContentsGradient Tool', '1. Add a new adjustment layer  and select the ', 'Gradient tool. ', '2. Select the Gradient tool  and drag from where the ', 'water meets the rocks and up a bit. The gradient ', 'can be adjusted later using the handles on the ', 'gradient. See #4.  ', '3. Add a new layer by clicking the \"+\". Set Saturation  ', 'to a negative value to decrease saturation. Drag a ', 'new gradient. This time in the opposite direction. ', 'Fine-tune the setting for Saturation for the desired ', 'result.', '4.  Gradient manupulation handles:  ', ' ', 'A: The white outline indicates active side. Modify ', 'the gradient by moving this handle.  ', ' ', 'B: Centre handle - Moves the gradient.  ', ' ', 'C: Inactive side. Modify the gradient by moving this ', 'handle.Adjustments Layers âˆ’ Gradient tool', '1', '3', '42', 'A', 'AB', 'BC', 'C']\n",
      "\n",
      "downloading LLM model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amlanchatterjee/PycharmProjects/rag-llm/venv/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `HuggingFaceHub` was deprecated in LangChain 0.0.21 and will be removed in 0.2.0. Use HuggingFaceEndpoint instead.\n",
      "  warn_deprecated(\n",
      "/Users/amlanchatterjee/PycharmProjects/rag-llm/venv/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully Loaded llm model\n",
      "Loading QA...\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
